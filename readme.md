# EVA ðŸ¤–

EVA is a **local, privacyâ€‘first AI assistant** designed to run entirely on your machine. The goal of the project is to provide a fast, customizable assistant with **speechâ€‘toâ€‘text (STT)**, **textâ€‘toâ€‘speech (TTS)**, and modular AI models â€” without relying on cloud APIs.

Built with a desktopâ€‘first mindset, EVA focuses on acceptable latency, offline support, and full control over models and settings.

---

## âœ¨ Features

- ðŸ–¥ï¸ **Desktop App (Electron)**
- ðŸŽ™ï¸ **Speechâ€‘toâ€‘Text (Whisper-based)**
- ðŸ—£ï¸ **Textâ€‘toâ€‘Speech (local & free models)**
- ðŸ§  **Pluggable Assistant Models**
- ðŸ”‘ **Wakeâ€‘word support (Porcupine)**
- âš™ï¸ **Fully configurable settings UI**
- ðŸ”’ **Runs locally â€“ no data leaves your machine**

---

## ðŸ§± Tech Stack

- **Frontend:** Electron + React (TSX)
- **Backend / Main Process:** Node.js
- **STT:** OpenAI Whisper (local)
- **TTS:** Local neural TTS engines (offline)
- **Wake Word:** Porcupine
- **IPC:** Electron IPC for settings & events

---

## ðŸ“‚ Project Structure

```text
PROJECT_EVA/
â”œâ”€ app/                        # Main Electron application
â”‚  â”œâ”€ resources/               # Static resources
â”‚  â”œâ”€ src/                     # Application source code
â”‚  â”‚  â”œâ”€ chat/                 # Chat UI & conversation logic
â”‚  â”‚  â”œâ”€ eva-core/             # Core AI logic & orchestration
â”‚  â”‚  â”œâ”€ ipc/                  # IPC channels (main â†” renderer)
â”‚  â”‚  â”œâ”€ main/                 # Electron main process
â”‚  â”‚  â”œâ”€ preload/              # Secure preload bridge
â”‚  â”‚  â”œâ”€ renderer/             # Frontend UI (React / TSX)
â”‚  â”‚  â”œâ”€ types/                # Shared TypeScript types
â”‚  â”‚  â”œâ”€ utils/                # Utility helpers
â”‚  â”‚  â””â”€ workers/              # Background workers (TTS)
â”‚  â”‚
â”‚  â”œâ”€ electron-builder.yml
â”‚  â”œâ”€ electron.vite.config.ts
â”‚  â”œâ”€ eslint.config.mjs
â”‚  â”œâ”€ postcss.config.mjs
â”‚  â”œâ”€ tsconfig.json
â”‚  â”œâ”€ tsconfig.node.json
â”‚  â”œâ”€ tsconfig.web.json
â”‚  â””â”€ package.json
â”‚
â”œâ”€ listener/                   # Standalone audio listener service
â”‚  â”œâ”€ whisper/                 # Whisper STT integration
â”‚  â”œâ”€ index.js                 # Listener entry point
â”‚  â”œâ”€ .env                     # Runtime environment variables
â”‚  â”œâ”€ package.json
â”‚  â””â”€ package-lock.json
â”‚
â”œâ”€ models/                     # Centralized AI models (LLM, TTS, STT) Used for Development
â”‚
â””â”€ settings/                   # App & service configuration

```

### app/

- Full Electron + Vite application (UI, IPC, core logic)

### listener/

- Lightweight Node service for always-on audio & Whisper STT

### models/

- Central shared model storage, reused by both app and listener

### settings/

- Persistent user & system configuration

---

## âš™ï¸ Configuration

EVA allows model-level configuration directly from the UI.

### Model Settings

- **Whisper STT Model** â€“ speech-to-text model
- **Kokoro TTS Model** â€“ text-to-speech model
- **Assistant Model** â€“ core LLM powering responses
- **Porcupine Keywords Model** â€“ wake-word detection

Settings are persisted locally

---

## ðŸš€ Getting Started

### Prerequisites

- Node.js **18+**
- npm or pnpm
- Windows / Linux (macOS experimental)

#### Required Downloads

- A llama friendly model has to be downloaded and stored somewhere where it can be accessed by the application ( AI Agent model )

- A Whisper STT Model model has to be downloaded and stored somewhere where it can be accessed by the application

- A Porcupine Keywords Model has to be downloaded and stored somewhere where it can be accessed by the application

- A Kokoro Model has to be downloaded and stored somewhere where it can be accessed by the application

### Installation

You can either download the available binaries ( windows only for now ) or clone this repo and build it for yourself.

#### Recommended models

- [Recommended AI Agent model (Qwen 2.5)](https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF/tree/main)

- [Picovoice/Porcupine Model for wake-word](https://picovoice.ai/platform/porcupine/)

- [Whisper ggml models](https://huggingface.co/ggerganov/whisper.cpp/tree/main)

- [Kokoro TTS ONNX models](https://huggingface.co/onnx-community/Kokoro-82M-v1.0-ONNX/tree/main)

- A tutorial video will be created after the first release of the application

```bash
git clone https://github.com/manicodes87/Project_EVA.git
```

```bash
npm install
```

### Development

```bash
npm run dev
```

### Build

```bash
npm run build
```

---

## ðŸŽ§ Performance Notes

- Designed to run **without a GPU** (GPU optional)
- STT latency depends on Whisper model size
- TTS is optimized for low-latency responses

---

## ðŸ›£ï¸ Roadmap

- [ ] Conversation memory
- [ ] Crossâ€‘platform builds

---

## ðŸ§  Philosophy

EVA is built around three core ideas:

1. **Local-first** â€“ your data stays yours
2. **Modular** â€“ swap models easily
3. **Fast** â€“ minimal overhead, maximum control

---

## ðŸ“œ License

MIT License

---

## ðŸ™Œ Contributing

PRs, ideas, and experiments are welcome. EVA is a playground for building serious local AI tooling.

---

> _EVA is not meant to replace cloud assistants â€” itâ€™s meant to outperform them locally._
